{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc78b03-4a78-4e46-9c98-37ddc56e0627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 29 17:07:12 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           On  |   00000000:00:17.0 Off |                    0 |\n",
      "| N/A   38C    P0             41W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-16GB           On  |   00000000:00:18.0 Off |                    0 |\n",
      "| N/A   36C    P0             42W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-16GB           On  |   00000000:00:19.0 Off |                    0 |\n",
      "| N/A   37C    P0             44W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-16GB           On  |   00000000:00:1A.0 Off |                    0 |\n",
      "| N/A   38C    P0             43W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2-16GB           On  |   00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   37C    P0             42W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2-16GB           On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   38C    P0             43W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2-16GB           On  |   00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   38C    P0             44W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2-16GB           On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   38C    P0             45W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe4fc0c-d9f2-4883-9b83-448ff6ebb2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton \n",
    "import triton.language as tl\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6db81cd7-a58d-4df8-a803-b4c1d4c1ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _attn_fwd_inner(\n",
    "    O_block,\n",
    "    l_i,\n",
    "    m_i,\n",
    "    Q_block,\n",
    "    K_block_ptr,\n",
    "    V_block_ptr,\n",
    "    block_index_q,\n",
    "    softmax_scale,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    BLOCK_SIZE_KV: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "    offs_q: tl.constexpr,\n",
    "    offs_kv: tl.constexpr,\n",
    "    SEQ_LEN: tl.constexpr,\n",
    "):\n",
    "    # range of values handled by this stage\n",
    "    if STAGE == 1:\n",
    "        # From 0 to the left of the diagonal\n",
    "        lo, hi = 0, block_index_q * BLOCK_SIZE_Q\n",
    "    elif STAGE == 2:\n",
    "        # Used only for the block in which there is transition between non-masked and masked keys\n",
    "        lo, hi = block_index_q * BLOCK_SIZE_Q, (block_index_q + 1) * BLOCK_SIZE_Q\n",
    "        lo = tl.multiple_of(lo, BLOCK_SIZE_Q)\n",
    "    else:\n",
    "        # Only used for non-causal attention\n",
    "        lo, hi = 0, SEQ_LEN\n",
    "\n",
    "    K_block_ptr = tl.advance(K_block_ptr, (0, lo))\n",
    "    V_block_ptr = tl.advance(V_block_ptr, (lo, 0))\n",
    "\n",
    "    # loop over k, v and update accumulator\n",
    "    for start_kv in range(lo, hi, BLOCK_SIZE_KV):\n",
    "        # Just let the compiler know that start_n is a multiple of BLOCK_N, so the compiler can do optimizations\n",
    "        start_kv = tl.multiple_of(start_kv, BLOCK_SIZE_KV)\n",
    "\n",
    "        # -- compute qk ----\n",
    "        K_block = tl.load(K_block_ptr)\n",
    "        QK_block = tl.dot(Q_block, K_block)\n",
    "\n",
    "        if STAGE == 2:\n",
    "            mask = offs_q[:, None] >= (start_kv + offs_kv[None, :])\n",
    "            QK_block = QK_block * softmax_scale + tl.where(mask, 0, -1.0e6)\n",
    "            m_ij = tl.maximum(m_i, tl.max(QK_block, 1))\n",
    "            QK_block -= m_ij[:, None]\n",
    "        else:\n",
    "            # Compute the maximum value of qk or keep the old max value\n",
    "            m_ij = tl.maximum(m_i, tl.max(QK_block, 1) * softmax_scale)\n",
    "            QK_block = QK_block * softmax_scale - m_ij[:, None]\n",
    "\n",
    "        # Compute the exponential of each dot product, so now we are computing exp(qk_ij - m_ij)\n",
    "        P_block = tl.math.exp(QK_block)\n",
    "        # Compute the sum by rows of the attention scores\n",
    "        l_ij = tl.sum(P_block, 1)\n",
    "\n",
    "        # This is the correction factor for the previous l_i\n",
    "        alpha = tl.math.exp(m_i - m_ij)\n",
    "        # Apply the correction factor to the previous l_i and add the new l_ij\n",
    "        l_i = l_i * alpha + l_ij\n",
    "\n",
    "        V_block = tl.load(V_block_ptr)\n",
    "        P_block = P_block.to(tl.float16)\n",
    "        # This computes the following: O_new = P x V + O_old * alpha\n",
    "        O_block = O_block * alpha[:, None]\n",
    "        O_block = tl.dot(P_block, V_block, O_block)\n",
    "\n",
    "        m_i = m_ij\n",
    "\n",
    "        # Move to the next block of K and V\n",
    "        V_block_ptr = tl.advance(V_block_ptr, (BLOCK_SIZE_KV, 0))\n",
    "        K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_SIZE_KV))\n",
    "    return O_block, l_i, m_i\n",
    "\n",
    "\n",
    "@triton.autotune(\n",
    "    [\n",
    "        triton.Config(\n",
    "            {\"BLOCK_SIZE_Q\": BLOCK_SIZE_Q, \"BLOCK_SIZE_KV\": BLOCK_SIZE_KV},\n",
    "            num_stages=num_stages,\n",
    "            num_warps=num_warps,\n",
    "        )\n",
    "        for BLOCK_SIZE_Q in [32, 64, 128]\n",
    "        for BLOCK_SIZE_KV in [32, 64]\n",
    "        for num_stages in ([3, 4])\n",
    "        for num_warps in [2, 4, 8]\n",
    "    ],\n",
    "    key=[\"SEQ_LEN\", \"HEAD_DIM\"],\n",
    ")\n",
    "@triton.jit\n",
    "def _attn_fwd(\n",
    "    Q,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    K,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    V,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    softmax_scale,\n",
    "    M,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN\n",
    "    O,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    stride_Q_batch,\n",
    "    stride_Q_head,\n",
    "    stride_Q_seq,\n",
    "    stride_Q_dim,\n",
    "    stride_K_batch,\n",
    "    stride_K_head,\n",
    "    stride_K_seq,\n",
    "    stride_K_dim,\n",
    "    stride_V_batch,\n",
    "    stride_V_head,\n",
    "    stride_V_seq,\n",
    "    stride_V_dim,\n",
    "    stride_O_batch,\n",
    "    stride_O_head,\n",
    "    stride_O_seq,\n",
    "    stride_O_dim,\n",
    "    BATCH_SIZE,\n",
    "    NUM_HEADS: tl.constexpr,\n",
    "    SEQ_LEN: tl.constexpr,\n",
    "    HEAD_DIM: tl.constexpr,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    BLOCK_SIZE_KV: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "):\n",
    "    tl.static_assert(BLOCK_SIZE_KV <= HEAD_DIM)\n",
    "\n",
    "    # This indicate which block in the sequence length to process\n",
    "    block_index_q = tl.program_id(0)\n",
    "\n",
    "    # This indicates which head and batch to process. Each program is associated with a single head of a single batch\n",
    "    index_batch_head = tl.program_id(1)\n",
    "    # This indicate which batch this program is associated with (each batch has NUM_HEADS heads)\n",
    "    index_batch = index_batch_head // NUM_HEADS\n",
    "    # This indicate the position of the head in the batch\n",
    "    index_head = index_batch_head % NUM_HEADS\n",
    "    \n",
    "    # This allows to get the (N_CTX, HEAD_DIM) block in the Q, K, V by selecting indexing it by batch and head\n",
    "    qvk_offset = (\n",
    "        index_batch.to(tl.int64) * stride_Q_batch\n",
    "        + index_head.to(tl.int64) * stride_Q_head\n",
    "    )\n",
    "\n",
    "    Q_block_ptr = tl.make_block_ptr(\n",
    "        base=Q + qvk_offset,\n",
    "        shape=(SEQ_LEN, HEAD_DIM),\n",
    "        strides=(stride_Q_seq, stride_Q_dim),\n",
    "        offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
    "        block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    V_block_ptr = tl.make_block_ptr(\n",
    "        base=V + qvk_offset,\n",
    "        shape=(SEQ_LEN, HEAD_DIM),\n",
    "        strides=(stride_V_seq, stride_V_dim),\n",
    "        offsets=(0, 0),\n",
    "        block_shape=(BLOCK_SIZE_KV, HEAD_DIM),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    K_block_ptr = tl.make_block_ptr(\n",
    "        base=K + qvk_offset,\n",
    "        shape=(HEAD_DIM, SEQ_LEN),\n",
    "        strides=(\n",
    "            stride_K_dim,\n",
    "            stride_K_seq,\n",
    "        ),  # We invert the strides w.r.t Q, so we transpose the matrix\n",
    "        offsets=(0, 0),\n",
    "        block_shape=(HEAD_DIM, BLOCK_SIZE_KV),\n",
    "        order=(0, 1),\n",
    "    )\n",
    "\n",
    "    O_block_ptr = tl.make_block_ptr(\n",
    "        base=O + qvk_offset,\n",
    "        shape=(SEQ_LEN, HEAD_DIM),\n",
    "        strides=(stride_O_seq, stride_O_dim),\n",
    "        offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
    "        block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
    "        order=(1, 0),\n",
    "    )\n",
    "\n",
    "    # offs_q: the offsets for the tokens in the Q to process\n",
    "    offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q)\n",
    "    # offs_kv: the offsets for the tokens in the K and V sequence to process\n",
    "    offs_kv = tl.arange(0, BLOCK_SIZE_KV)\n",
    "\n",
    "    # m_i: the running maximum. We have one for each query\n",
    "    m_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) - float(\"inf\")\n",
    "    # l_i: the running sum. We have one for each query (as we sum the attention scores by rows)\n",
    "    l_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) + 1.0\n",
    "    # acc: the accumulator for the output, which is a group of rows of the O matrix\n",
    "    O_block = tl.zeros([BLOCK_SIZE_Q, HEAD_DIM], dtype=tl.float32)\n",
    "\n",
    "    # load the blocks of Q: it will stay in SRAM throughout\n",
    "    Q_block = tl.load(Q_block_ptr)\n",
    "\n",
    "    # Stage: 3 if causal, else 1\n",
    "\n",
    "    if STAGE == 1 or STAGE == 3:\n",
    "        # This step runs for non-causal attention or for the blocks to the left of the diagonal in the causal attention\n",
    "        O_block, l_i, m_i = _attn_fwd_inner(\n",
    "            O_block,\n",
    "            l_i,\n",
    "            m_i,\n",
    "            Q_block,\n",
    "            K_block_ptr,\n",
    "            V_block_ptr,\n",
    "            block_index_q,\n",
    "            softmax_scale,\n",
    "            BLOCK_SIZE_Q,\n",
    "            BLOCK_SIZE_KV,\n",
    "            4 - STAGE,\n",
    "            offs_q,\n",
    "            offs_kv,\n",
    "            SEQ_LEN,\n",
    "        )\n",
    "\n",
    "    if STAGE == 3:\n",
    "        # This step runs for the blocks to the right of the diagonal in the causal attention\n",
    "        O_block, l_i, m_i = _attn_fwd_inner(\n",
    "            O_block,\n",
    "            l_i,\n",
    "            m_i,\n",
    "            Q_block,\n",
    "            K_block_ptr,\n",
    "            V_block_ptr,\n",
    "            block_index_q,\n",
    "            softmax_scale,\n",
    "            BLOCK_SIZE_Q,\n",
    "            BLOCK_SIZE_KV,\n",
    "            2,\n",
    "            offs_q,\n",
    "            offs_kv,\n",
    "            SEQ_LEN,\n",
    "        )\n",
    "    # epilogue\n",
    "    m_i += tl.math.log(\n",
    "        l_i\n",
    "    )  # This is needed to compute the logsumexp for the backwards pass\n",
    "    O_block = O_block / l_i[:, None]\n",
    "    m_ptrs = M + index_batch_head * SEQ_LEN + offs_q\n",
    "    tl.store(m_ptrs, m_i)\n",
    "    tl.store(O_block_ptr, O_block.to(O.type.element_ty))\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def _attn_bwd_preprocess(\n",
    "    O,\n",
    "    dO,\n",
    "    D,\n",
    "    SEQ_LEN,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    HEAD_DIM: tl.constexpr,\n",
    "):\n",
    "    block_index_q = tl.program_id(0)\n",
    "    offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q)\n",
    "    index_batch_head = tl.program_id(1)\n",
    "    offs_dim = tl.arange(0, HEAD_DIM)\n",
    "\n",
    "    \n",
    "    # Load a single block of BLOCK_SIZE_Q rows of O\n",
    "    O_block = tl.load(\n",
    "        O\n",
    "        + index_batch_head * HEAD_DIM * SEQ_LEN\n",
    "        + offs_q[:, None] * HEAD_DIM\n",
    "        + offs_dim[None, :]\n",
    "    )\n",
    "    # Load a single block of BLOCK_SIZE_Q rows of dO\n",
    "    dO_block = tl.load(\n",
    "        dO\n",
    "        + index_batch_head * HEAD_DIM * SEQ_LEN\n",
    "        + offs_q[:, None] * HEAD_DIM\n",
    "        + offs_dim[None, :]\n",
    "    ).to(tl.float32)\n",
    "    # Compute the D block\n",
    "    D_block = tl.sum(dO_block * O_block, axis=1)  # Shape: (BLOCK_SIZE_Q,)\n",
    "    # Store the D block\n",
    "    D_block_ptrs = D + index_batch_head * SEQ_LEN + offs_q\n",
    "    tl.store(D_block_ptrs, D_block)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def _attn_bwd_dq(\n",
    "    Q,\n",
    "    K,\n",
    "    V,\n",
    "    softmax_scale,\n",
    "    dO,\n",
    "    dQ,\n",
    "    dK,\n",
    "    dV,\n",
    "    M,\n",
    "    D,\n",
    "    stride_batch,\n",
    "    stride_head,\n",
    "    stride_seq,\n",
    "    stride_dim,\n",
    "    NUM_HEADS,\n",
    "    SEQ_LEN,\n",
    "    BLOCK_Q: tl.constexpr,\n",
    "    BLOCK_KV: tl.constexpr,\n",
    "    HEAD_DIM: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "):\n",
    "    index_batch_head = tl.program_id(2)\n",
    "    index_batch = index_batch_head // NUM_HEADS\n",
    "    index_head = index_batch_head % NUM_HEADS\n",
    "    offset_batch_head = (stride_batch * index_batch + stride_head * index_head).to(\n",
    "        tl.int64\n",
    "    )\n",
    "    # This is the offset that allows us to select the right sequence given the batch and head.\n",
    "    offset_batch_head_seq = (index_batch_head * SEQ_LEN).to(tl.int64)\n",
    "\n",
    "    # Make sure the pointers are in the right place w.r.t batch and head\n",
    "    # The reason we don't access the blocks through make_block_ptr is because we need to use the range of offsets to apply the masking\n",
    "    Q += offset_batch_head\n",
    "    K += offset_batch_head\n",
    "    V += offset_batch_head\n",
    "    dO += offset_batch_head\n",
    "    dQ += offset_batch_head\n",
    "    dK += offset_batch_head\n",
    "    dV += offset_batch_head\n",
    "\n",
    "    # Make sure the pointers are in the right place w.r.t batch, head and sequence\n",
    "    M += offset_batch_head_seq\n",
    "    D += offset_batch_head_seq\n",
    "\n",
    "    # load scales\n",
    "    offs_dim = tl.arange(0, HEAD_DIM)\n",
    "\n",
    "    index_block_kv = tl.program_id(0)\n",
    "\n",
    "    start_q = index_block_kv * BLOCK_Q\n",
    "    \n",
    "    offs_q = start_q + tl.arange(0, BLOCK_Q)\n",
    "\n",
    "    Q_block = tl.load(Q + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim)\n",
    "    dQ_block = tl.zeros([BLOCK_Q, HEAD_DIM], dtype=tl.float32)\n",
    "    dO_block = tl.load(\n",
    "        dO + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "    )\n",
    "\n",
    "    M_block = tl.load(M + offs_q)\n",
    "    M_block = M_block[:, None]\n",
    "\n",
    "    offs_kv = tl.arange(0, BLOCK_KV)\n",
    "\n",
    "    # We access the K and V as transposed blocks\n",
    "    kT_ptrs = K + offs_kv[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
    "    vT_ptrs = V + offs_kv[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
    "\n",
    "    Di = tl.load(D + offs_q)\n",
    "\n",
    "    curr_kv = 0\n",
    "    num_steps = SEQ_LEN // BLOCK_KV\n",
    "    for blk_idx in range(num_steps):\n",
    "        K_T_block = tl.load(kT_ptrs)\n",
    "        V_T_block = tl.load(vT_ptrs)\n",
    "        QK_block = softmax_scale * tl.dot(Q_block, K_T_block)\n",
    "        P_block = tl.math.exp(QK_block - M_block)\n",
    "\n",
    "        if STAGE == 3:\n",
    "            # Autoregressive masking.\n",
    "            offs_kv = curr_kv + tl.arange(0, BLOCK_KV)\n",
    "            mask_block = offs_q[:, None] >= offs_kv[None, :]\n",
    "            P_block = tl.where(mask_block, P_block, 0.0)\n",
    "\n",
    "        # Compute dP and dS.\n",
    "        dP_block = tl.dot(dO_block, V_T_block).to(tl.float32)\n",
    "        dS_block = P_block * (dP_block - Di[:, None])\n",
    "        dS_block = dS_block.to(tl.float16)\n",
    "        # Compute dQ.\n",
    "        # NOTE: We need to de-scale dq in the end, because kT was pre-scaled.\n",
    "        dQ_block += softmax_scale * tl.dot(dS_block, tl.trans(K_T_block))\n",
    "        # Increment pointers.\n",
    "        curr_kv += BLOCK_KV\n",
    "        kT_ptrs += BLOCK_KV * stride_seq\n",
    "        vT_ptrs += BLOCK_KV * stride_seq\n",
    "\n",
    "    dQ_block_ptrs = dQ + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "    tl.store(dQ_block_ptrs, dQ_block)\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def _attn_bwd_dk_dv(\n",
    "    Q,\n",
    "    K,\n",
    "    V,\n",
    "    softmax_scale,\n",
    "    dO,\n",
    "    dQ,\n",
    "    dK,\n",
    "    dV,\n",
    "    M,\n",
    "    D,\n",
    "    stride_batch,\n",
    "    stride_head,\n",
    "    stride_seq,\n",
    "    stride_dim,\n",
    "    NUM_HEADS,\n",
    "    SEQ_LEN,\n",
    "    BLOCK_Q: tl.constexpr,\n",
    "    BLOCK_KV: tl.constexpr,\n",
    "    HEAD_DIM: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "):\n",
    "    index_batch_head = tl.program_id(2)\n",
    "    index_batch = index_batch_head // NUM_HEADS\n",
    "    index_head = index_batch_head % NUM_HEADS\n",
    "    offset_batch_head = (stride_batch * index_batch + stride_head * index_head).to(\n",
    "        tl.int64\n",
    "    )\n",
    "    # This is the offset that allows us to select the right sequence given the batch and head.\n",
    "    offset_batch_head_seq = (index_batch_head * SEQ_LEN).to(tl.int64)\n",
    "\n",
    "    # Make sure the pointers are in the right place w.r.t batch and head\n",
    "    # The reason we don't access the blocks through make_block_ptr is because we need to use the range of offsets to apply the masking\n",
    "    Q += offset_batch_head\n",
    "    K += offset_batch_head\n",
    "    V += offset_batch_head\n",
    "    dO += offset_batch_head\n",
    "    dQ += offset_batch_head\n",
    "    dK += offset_batch_head\n",
    "    dV += offset_batch_head\n",
    "\n",
    "    # Make sure the pointers are in the right place w.r.t batch, head and sequence\n",
    "    M += offset_batch_head_seq\n",
    "    D += offset_batch_head_seq\n",
    "\n",
    "    # load scales\n",
    "    offs_dim = tl.arange(0, HEAD_DIM)\n",
    "\n",
    "    index_block_kv = tl.program_id(0)\n",
    "    start_kv = index_block_kv * BLOCK_KV\n",
    "\n",
    "    offs_kv = start_kv + tl.arange(0, BLOCK_KV)\n",
    "\n",
    "    dV_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n",
    "    dK_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n",
    "\n",
    "    # load K and V: they stay in SRAM throughout the inner loop.\n",
    "    K_block = tl.load(\n",
    "        K + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "    )  # Shape: (BLOCK_KV1, HEAD_DIM)\n",
    "    V_block = tl.load(\n",
    "        V + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "    )  # Shape: (BLOCK_KV1, HEAD_DIM)\n",
    "\n",
    "    offs_q = tl.arange(0, BLOCK_Q)\n",
    "\n",
    "    # We access the Q as a transposed array, so that's why we treat offs_q as a column vector ans offs_dim as a row vector\n",
    "    # This is equivalent to doing:\n",
    "    # q_ptrs = Q + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "    # qT_ptrs = tl.trans(q_ptrs)\n",
    "    # We point to the first BLOCK_Q rows of Q for both the qT and dO pointers, inside the for loop we will move forward by BLOCK_Q rows at each iteration.\n",
    "    qT_ptrs = Q + offs_q[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
    "    dO_ptrs = dO + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "\n",
    "    # Iterates over the sequence dimension of the query\n",
    "    curr_q = 0\n",
    "    num_steps = SEQ_LEN // BLOCK_Q\n",
    "    for blk_idx in range(num_steps):\n",
    "        # Load a block of Q\n",
    "        qT_block = tl.load(qT_ptrs)\n",
    "        # Load the logsumexp values for the queries in the current block\n",
    "        offs_q = curr_q + tl.arange(0, BLOCK_Q)\n",
    "        m = tl.load(M + offs_q)\n",
    "\n",
    "        # This gives us (QK^T)^T = (K^T)^T(Q^T) = K(Q^T) = P^T\n",
    "        QK_T_block = softmax_scale * tl.dot(K_block, qT_block)\n",
    "        # We apply the softmax by using the logsumexp trick\n",
    "        P_T_block = tl.math.exp(QK_T_block - m[None, :])\n",
    "\n",
    "        if STAGE == 3:\n",
    "            # Autoregressive masking.\n",
    "            # mask is True for all values that DO NOT NEED TO BE MASKED\n",
    "            mask_block = (\n",
    "                offs_q[None, :] >= offs_kv[:, None]\n",
    "            )  # Shape: (BLOCK_KV1, BLOCK_Q1)\n",
    "            # Replace all the masked values with 0.\n",
    "            # In this case we do not need to mask with -Inf before applying the softmax since we already computed the normalization factors (stored in \"m\")\n",
    "            P_T_block = tl.where(mask_block, P_T_block, 0.0)\n",
    "\n",
    "        dO_block = tl.load(dO_ptrs)\n",
    "        # According to the formula: dV_new = dV_old + P^T x dO, where x is the matrix multiplication\n",
    "        dV_block += tl.dot(P_T_block.to(tl.float16), dO_block)\n",
    "\n",
    "        # Delta = rowsum(O * dO) where * is the element-wise product\n",
    "        Di = tl.load(D + offs_q)\n",
    "\n",
    "        # dP = dO x V^T, so dP^T = V x dO^T\n",
    "        # Where x is the matrix multiplication\n",
    "        dpT_block = tl.dot(V_block, tl.trans(dO_block)).to(tl.float32)\n",
    "\n",
    "        # We know that dS = P * (dP - Delta), so dS^T = P^T * (dP^T - Delta^T)\n",
    "\n",
    "        dS_T_block = P_T_block * (dpT_block - Di[None, :])\n",
    "        dS_T_block = dS_T_block.to(tl.float16)\n",
    "\n",
    "        # According to the formula on the paper: dK_new = dK_old + dS^T x Q\n",
    "        dK_block += softmax_scale * tl.dot(dS_T_block, tl.trans(qT_block))\n",
    "        # Increment pointers.\n",
    "        curr_q += BLOCK_Q\n",
    "        qT_ptrs += BLOCK_Q * stride_seq\n",
    "        dO_ptrs += BLOCK_Q * stride_seq\n",
    "\n",
    "    # Write back dV.\n",
    "    dV_block_ptrs = dV + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "    tl.store(dV_block_ptrs, dV_block)\n",
    "\n",
    "    # Write back dK.\n",
    "    dK_block_ptrs = dK + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
    "    tl.store(dK_block_ptrs, dK_block)\n",
    "\n",
    "\n",
    "class TritonAttention(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, Q, K, V, causal, softmax_scale):\n",
    "        HEAD_DIM_Q, HEAD_DIM_K = Q.shape[-1], K.shape[-1]\n",
    "        HEAD_DIM_V = V.shape[-1]\n",
    "\n",
    "        BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM = Q.shape\n",
    "\n",
    "        assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_K == HEAD_DIM_V\n",
    "\n",
    "        O = torch.empty_like(Q)\n",
    "        stage = 3 if causal else 1\n",
    "\n",
    "        grid = lambda args: (\n",
    "            triton.cdiv(SEQ_LEN, args[\"BLOCK_SIZE_Q\"]),\n",
    "            BATCH_SIZE * NUM_HEADS,\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        # M is the logsumexp for the backward pass, one for each query\n",
    "        M = torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN), device=Q.device, dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        print(f\"Forward pass start: Q shape {Q.shape}, K shape {K.shape}, V shape {V.shape}\")\n",
    "\n",
    "        # Timing the kernel launch\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        \n",
    "        _attn_fwd[grid](\n",
    "            Q=Q,\n",
    "            K=K,\n",
    "            V=V,\n",
    "            softmax_scale=softmax_scale,\n",
    "            M=M,\n",
    "            O=O,\n",
    "            stride_Q_batch=Q.stride(0),\n",
    "            stride_Q_head=Q.stride(1),\n",
    "            stride_Q_seq=Q.stride(2),\n",
    "            stride_Q_dim=Q.stride(3),\n",
    "            stride_K_batch=K.stride(0),\n",
    "            stride_K_head=K.stride(1),\n",
    "            stride_K_seq=K.stride(2),\n",
    "            stride_K_dim=K.stride(3),\n",
    "            stride_V_batch=V.stride(0),\n",
    "            stride_V_head=V.stride(1),\n",
    "            stride_V_seq=V.stride(2),\n",
    "            stride_V_dim=V.stride(3),\n",
    "            stride_O_batch=O.stride(0),\n",
    "            stride_O_head=O.stride(1),\n",
    "            stride_O_seq=O.stride(2),\n",
    "            stride_O_dim=O.stride(3),\n",
    "            BATCH_SIZE=Q.shape[0],\n",
    "            NUM_HEADS=Q.shape[1],\n",
    "            SEQ_LEN=Q.shape[2],\n",
    "            HEAD_DIM=HEAD_DIM_K,\n",
    "            STAGE=stage,\n",
    "        )\n",
    "        \n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"_attn_fwd kernel execution time: {start_event.elapsed_time(end_event)} ms\")\n",
    "        \n",
    "        # Logging grid and chosen config\n",
    "        chosen_config = _attn_fwd.best_config\n",
    "        grid_dims = grid({'BLOCK_SIZE_Q': chosen_config.kwargs['BLOCK_SIZE_Q']})\n",
    "        print(f\"_attn_fwd grid dimensions: {grid_dims}\")\n",
    "        print(f\"_attn_fwd chosen config: BLOCK_SIZE_Q={chosen_config.kwargs['BLOCK_SIZE_Q']}, BLOCK_SIZE_KV={chosen_config.kwargs['BLOCK_SIZE_KV']}, num_warps={chosen_config.num_warps}, num_stages={chosen_config.num_stages}\")\n",
    "        \n",
    "        # Logging output shape\n",
    "        print(f\"Forward pass end: O shape {O.shape}\")\n",
    "\n",
    "        ctx.save_for_backward(Q, K, V, O, M)\n",
    "        ctx.grid = grid\n",
    "        ctx.softmax_scale = softmax_scale\n",
    "        ctx.HEAD_DIM = HEAD_DIM_K\n",
    "        ctx.causal = causal\n",
    "        return O\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dO):\n",
    "        Q, K, V, O, M = ctx.saved_tensors\n",
    "\n",
    "        assert dO.is_contiguous()\n",
    "        assert Q.stride() == K.stride() == V.stride() == O.stride() == dO.stride()\n",
    "        dQ = torch.empty_like(Q)\n",
    "        dK = torch.empty_like(K)\n",
    "        dV = torch.empty_like(V)\n",
    "\n",
    "        BATCH_SIZE, NUM_HEADS, SEQ_LEN = Q.shape[:3]\n",
    "        NUM_WARPS, NUM_STAGES = 4, 3\n",
    "        BLOCK_SIZE_MICRO, BLOCK_SIZE_MACRO = 32, 128\n",
    "\n",
    "        preprocess_grid = (SEQ_LEN // BLOCK_SIZE_MACRO, BATCH_SIZE * NUM_HEADS)\n",
    "        D = torch.empty_like(M)  # Shape: (BATCH_SIZE, NUM_HEADS, SEQ_LEN)\n",
    "\n",
    "        # Logging backward pass start\n",
    "        print(f\"Backward pass start: dO shape {dO.shape}\")\n",
    "        \n",
    "        # Preprocess kernel\n",
    "        print(f\"Launching _attn_bwd_preprocess with grid {preprocess_grid}\")\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        \n",
    "        # Compute all the elements Di\n",
    "        _attn_bwd_preprocess[preprocess_grid](\n",
    "            O=O,\n",
    "            dO=dO,\n",
    "            D=D,\n",
    "            SEQ_LEN=SEQ_LEN,\n",
    "            BLOCK_SIZE_Q=BLOCK_SIZE_MACRO,\n",
    "            HEAD_DIM=ctx.HEAD_DIM,\n",
    "        )\n",
    "\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"_attn_bwd_preprocess kernel execution time: {start_event.elapsed_time(end_event)} ms\")\n",
    "        print(f\"Preprocess output: D shape {D.shape}\")\n",
    "        \n",
    "        grid = (SEQ_LEN // BLOCK_SIZE_MACRO, 1, BATCH_SIZE * NUM_HEADS)\n",
    "\n",
    "        stage = 3 if ctx.causal else 1\n",
    "\n",
    "        # dK, dV kernel\n",
    "        print(f\"Launching _attn_bwd_dk_dv with grid {grid}\")\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        \n",
    "        # Fix KV and iterate through all the Q blocks\n",
    "        _attn_bwd_dk_dv[grid](\n",
    "            Q=Q,\n",
    "            K=K,\n",
    "            V=V,\n",
    "            softmax_scale=ctx.softmax_scale,\n",
    "            dO=dO,\n",
    "            dQ=dQ,\n",
    "            dK=dK,\n",
    "            dV=dV,\n",
    "            M=M,\n",
    "            D=D,\n",
    "            stride_batch=Q.stride(0),\n",
    "            stride_head=Q.stride(1),\n",
    "            stride_seq=Q.stride(2),\n",
    "            stride_dim=Q.stride(3),\n",
    "            NUM_HEADS=NUM_HEADS,\n",
    "            SEQ_LEN=SEQ_LEN,\n",
    "            BLOCK_Q=BLOCK_SIZE_MICRO,\n",
    "            BLOCK_KV=BLOCK_SIZE_MACRO,\n",
    "            HEAD_DIM=ctx.HEAD_DIM,\n",
    "            STAGE=stage,\n",
    "            num_warps=NUM_WARPS,\n",
    "            num_stages=NUM_STAGES,\n",
    "        )\n",
    "\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"_attn_bwd_dk_dv kernel execution time: {start_event.elapsed_time(end_event)} ms\")\n",
    "        \n",
    "        \n",
    "        # dQ kernel\n",
    "        print(f\"Launching _attn_bwd_dq with grid {grid}\")\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "        \n",
    "        # Fix Q and iterate through all the KV block\n",
    "        _attn_bwd_dq[grid](\n",
    "            Q=Q,\n",
    "            K=K,\n",
    "            V=V,\n",
    "            softmax_scale=ctx.softmax_scale,\n",
    "            dO=dO,\n",
    "            dQ=dQ,\n",
    "            dK=dK,\n",
    "            dV=dV,\n",
    "            M=M,\n",
    "            D=D,\n",
    "            stride_batch=Q.stride(0),\n",
    "            stride_head=Q.stride(1),\n",
    "            stride_seq=Q.stride(2),\n",
    "            stride_dim=Q.stride(3),\n",
    "            NUM_HEADS=NUM_HEADS,\n",
    "            SEQ_LEN=SEQ_LEN,\n",
    "            BLOCK_Q=BLOCK_SIZE_MACRO,\n",
    "            BLOCK_KV=BLOCK_SIZE_MICRO,\n",
    "            HEAD_DIM=ctx.HEAD_DIM,\n",
    "            STAGE=stage,\n",
    "            num_warps=NUM_WARPS,\n",
    "            num_stages=NUM_STAGES,\n",
    "        )\n",
    "\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"_attn_bwd_dq kernel execution time: {start_event.elapsed_time(end_event)} ms\")\n",
    "        \n",
    "        # Logging output shapes\n",
    "        print(f\"Backward pass end: dQ shape {dQ.shape}, dK shape {dK.shape}, dV shape {dV.shape}\")\n",
    "        \n",
    "        return dQ, dK, dV, None, None\n",
    "\n",
    "\n",
    "def test_op(BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM, causal, dtype=torch.float16):\n",
    "    Q = (\n",
    "        torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "        .requires_grad_()\n",
    "    )\n",
    "    K = (\n",
    "        torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "        .requires_grad_()\n",
    "    )\n",
    "    V = (\n",
    "        torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "        .requires_grad_()\n",
    "    )\n",
    "\n",
    "    softmax_scale = 1 / (HEAD_DIM**0.5)\n",
    "    dO = torch.randn_like(Q)\n",
    "    \n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "    start_event.record()\n",
    "\n",
    "    # reference implementation\n",
    "    MASK = torch.tril(torch.ones((SEQ_LEN, SEQ_LEN), device=\"cuda\"))\n",
    "    P = torch.matmul(Q, K.transpose(2, 3)) * softmax_scale\n",
    "    if causal:\n",
    "        P[:, :, MASK == 0] = float(\"-inf\")\n",
    "    P = torch.softmax(P.float(), dim=-1).half()\n",
    "    ref_O = torch.matmul(P, V)\n",
    "    \n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()\n",
    "    pytorch_forward_time = start_event.elapsed_time(end_event)\n",
    "    print(f\"PyTorch Forward Time: {pytorch_forward_time} ms\")\n",
    "    \n",
    "    start_event.record()\n",
    "    ref_O.backward(dO)\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()\n",
    "    pytorch_backward_time = start_event.elapsed_time(end_event)\n",
    "    print(f\"PyTorch Backward Time: {pytorch_backward_time} ms\")\n",
    "    \n",
    "    ref_dV, V.grad = V.grad.clone(), None\n",
    "    ref_dK, K.grad = K.grad.clone(), None\n",
    "    ref_dQ, Q.grad = Q.grad.clone(), None\n",
    "\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "    start_event.record()\n",
    "    \n",
    "    # triton implementation\n",
    "    tri_out = TritonAttention.apply(Q, K, V, causal, softmax_scale).half()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()\n",
    "    triton_forward_time = start_event.elapsed_time(end_event)\n",
    "    print(f\"Triton Forward Time: {triton_forward_time} ms\")\n",
    "\n",
    "    # For measuring Triton Flash Attention backward time\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "    start_event.record()\n",
    "    \n",
    "    tri_out.backward(dO)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    tri_dV, V.grad = V.grad.clone(), None\n",
    "    tri_dK, K.grad = K.grad.clone(), None\n",
    "    tri_dQ, Q.grad = Q.grad.clone(), None\n",
    "\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()\n",
    "    triton_backward_time = start_event.elapsed_time(end_event)\n",
    "    print(f\"Triton Backward Time: {triton_backward_time} ms\")\n",
    "\n",
    "    # compare\n",
    "    rtol = 0.0\n",
    "    atol = 10\n",
    "    \n",
    "    assert torch.allclose(ref_O, tri_out, atol=atol, rtol=rtol)\n",
    "    assert torch.allclose(ref_dK, tri_dK, atol=atol, rtol=rtol)\n",
    "    assert torch.allclose(ref_dV, tri_dV, atol=atol, rtol=rtol)\n",
    "    assert torch.allclose(ref_dQ, tri_dQ, atol=atol, rtol=rtol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44cb47ab-00ea-42ed-8ba4-33d7c3877104",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7aa5863d-db24-41bc-9561-bba2af8c1e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Forward Time: 3.1549439430236816 ms\n",
      "PyTorch Backward Time: 6.338560104370117 ms\n",
      "Forward pass start: Q shape torch.Size([4, 16, 1024, 64]), K shape torch.Size([4, 16, 1024, 64]), V shape torch.Size([4, 16, 1024, 64])\n",
      "_attn_fwd kernel execution time: 0.43007999658584595 ms\n",
      "_attn_fwd grid dimensions: (16, 64, 1)\n",
      "_attn_fwd chosen config: BLOCK_SIZE_Q=64, BLOCK_SIZE_KV=64, num_warps=4, num_stages=3\n",
      "Forward pass end: O shape torch.Size([4, 16, 1024, 64])\n",
      "Triton Forward Time: 0.7106559872627258 ms\n",
      "Backward pass start: dO shape torch.Size([4, 16, 1024, 64])\n",
      "Launching _attn_bwd_preprocess with grid (8, 64)\n",
      "_attn_bwd_preprocess kernel execution time: 0.13516800105571747 ms\n",
      "Preprocess output: D shape torch.Size([4, 16, 1024])\n",
      "Launching _attn_bwd_dk_dv with grid (8, 1, 64)\n",
      "_attn_bwd_dk_dv kernel execution time: 1.3660160303115845 ms\n",
      "Launching _attn_bwd_dq with grid (8, 1, 64)\n",
      "_attn_bwd_dq kernel execution time: 1.2124160528182983 ms\n",
      "Backward pass end: dQ shape torch.Size([4, 16, 1024, 64]), dK shape torch.Size([4, 16, 1024, 64]), dV shape torch.Size([4, 16, 1024, 64])\n",
      "Triton Backward Time: 3.5788800716400146 ms\n",
      "PyTorch Forward Time: 2.781183958053589 ms\n",
      "PyTorch Backward Time: 4.420608043670654 ms\n",
      "Forward pass start: Q shape torch.Size([4, 16, 1024, 64]), K shape torch.Size([4, 16, 1024, 64]), V shape torch.Size([4, 16, 1024, 64])\n",
      "_attn_fwd kernel execution time: 0.5908480286598206 ms\n",
      "_attn_fwd grid dimensions: (16, 64, 1)\n",
      "_attn_fwd chosen config: BLOCK_SIZE_Q=64, BLOCK_SIZE_KV=64, num_warps=4, num_stages=3\n",
      "Forward pass end: O shape torch.Size([4, 16, 1024, 64])\n",
      "Triton Forward Time: 0.8683519959449768 ms\n",
      "Backward pass start: dO shape torch.Size([4, 16, 1024, 64])\n",
      "Launching _attn_bwd_preprocess with grid (8, 64)\n",
      "_attn_bwd_preprocess kernel execution time: 0.09932799637317657 ms\n",
      "Preprocess output: D shape torch.Size([4, 16, 1024])\n",
      "Launching _attn_bwd_dk_dv with grid (8, 1, 64)\n",
      "_attn_bwd_dk_dv kernel execution time: 1.2707840204238892 ms\n",
      "Launching _attn_bwd_dq with grid (8, 1, 64)\n",
      "_attn_bwd_dq kernel execution time: 1.1499520540237427 ms\n",
      "Backward pass end: dQ shape torch.Size([4, 16, 1024, 64]), dK shape torch.Size([4, 16, 1024, 64]), dV shape torch.Size([4, 16, 1024, 64])\n",
      "Triton Backward Time: 3.2491519451141357 ms\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "test_op(BATCH_SIZE=4, NUM_HEADS=16, SEQ_LEN=1024, HEAD_DIM=64, causal=True)\n",
    "test_op(BATCH_SIZE=4, NUM_HEADS=16, SEQ_LEN=1024, HEAD_DIM=64, causal=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec76f7-172e-4495-9ef5-45a1600e2e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a6c2a-2a97-4419-94dd-e57edbeab231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
